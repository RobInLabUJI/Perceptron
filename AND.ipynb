{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONKFCfoinuRhWH7oI6GWKN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RobInLabUJI/Perceptron/blob/main/AND.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning the AND function with a perceptron\n",
        "\n",
        "This is the truth table of the AND function.\n",
        "\n",
        "| Input $x_1$ | Input $x_2$ | Output $y$ |\n",
        "| :---: | :---: | :---: |\n",
        "| 0\t| 0\t| 0 |\n",
        "| 0\t| 1\t| 0 |\n",
        "| 1\t| 0\t| 0 |\n",
        "| 1\t| 1\t| 1 |\n",
        "\n",
        "So now we have a linear separability example using a single [perceptron](https://en.wikipedia.org/wiki/Perceptron)."
      ],
      "metadata": {
        "id": "iB8Id9JxnG8A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aei9fYRvnD3T"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sklearn.linear_model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_decision_boundary(net):\n",
        "    xmin, xmax = plt.xlim()\n",
        "    ymin, ymax = plt.ylim()\n",
        "    w = net.coef_[0]\n",
        "    b = net.intercept_[0]\n",
        "    if not w[1]==0:\n",
        "        a = -w[0] / w[1]\n",
        "        xx = np.linspace(xmin, xmax)\n",
        "        yy = a * xx - b / w[1]\n",
        "    elif not w[0]==0:\n",
        "        a = -w[1] / w[0]\n",
        "        yy = np.linspace(ymin, ymax)\n",
        "        xx = a * yy - b / w[0]\n",
        "    else:\n",
        "        xx = []\n",
        "        yy = []\n",
        "    plt.plot(xx,yy, 'b-')\n",
        "    plt.xlim([xmin,xmax])\n",
        "    plt.ylim([ymin,ymax])\n",
        "        \n",
        "def plot_data(x,y):\n",
        "    plt.rcParams['figure.figsize'] = (3.0, 3.0)\n",
        "    colormap = np.array(['r', 'k'])\n",
        "    plt.scatter(x[:,0], x[:,1], c=colormap[y.astype(int)], s=50);\n",
        "    plt.axis([-1.2,1.2,-1.2,1.2]);\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load in the data"
      ],
      "metadata": {
        "id": "3wyzp8MAntCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[0.,0.],\\\n",
        "              [0.,1.],\\\n",
        "              [1.,0.],\\\n",
        "              [1.,1.]])\n",
        "y = np.array([0.,0.,0.,1.])"
      ],
      "metadata": {
        "id": "omcv02lBnpNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot the data\n",
        "I always like to plot the data, I think its good practice to see what you are doing.\n",
        "\n",
        "Zeros are represented by red dots, and ones are black dots."
      ],
      "metadata": {
        "id": "uLYinKZonysc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_data(x, y)"
      ],
      "metadata": {
        "id": "8GrnRbDFnwo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the model\n",
        "Create a [perceptron object](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html)."
      ],
      "metadata": {
        "id": "jmDeyisuoA3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = sklearn.linear_model.Perceptron(max_iter=1, tol=1e-3, warm_start=True)"
      ],
      "metadata": {
        "id": "cKWMrQ6wn1TK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train\n",
        "Repeat the following cell (`Ctrl+Enter`) until the model converges."
      ],
      "metadata": {
        "id": "AGVP6bHZoGpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net.fit(x,y)\n",
        "print(\"Coefficient 0: %6.3f\" % net.coef_[0,0])\n",
        "print(\"Coefficient 1: %6.3f\" % net.coef_[0,1])\n",
        "print(\"         Bias: %6.3f\" % net.intercept_)\n",
        "plot_data(x, y)\n",
        "plot_decision_boundary(net)\n",
        "print('    Target: %s' % np.array_str(y))\n",
        "print('Prediction: %s' % np.array_str(net.predict(x)))"
      ],
      "metadata": {
        "id": "2t7ebUBaoEA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the model converges, the perceptron boundary completely separates the samples of each class (0's and 1's).\n",
        "\n",
        "The resulting plot should look like this:\n",
        "\n",
        "<img src=\"https://github.com/RobInLabUJI/Perceptron/raw/7592de1ff8d4c2459106700e5e26bd2ac983f1da/img/perceptron_and_converge.png\" align=\"right\">"
      ],
      "metadata": {
        "id": "gIfZIVRTofoj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "76LGvt9xobdq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}